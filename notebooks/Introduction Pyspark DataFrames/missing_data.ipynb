{"cells":[{"cell_type":"markdown","source":["### Missing Data\n\nOften data sources are incomplete, which means you will have missing data, you have 3 basic options for filling in missing data (you will personally have to make the decision for what is the right approach):\n\n* Just keep the missing data points.\n* Drop them missing data points (including the entire row)\n* Fill them in with some other value.\n\nLet's cover examples of each of these methods!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e09b5534-d4f9-4ac2-a4bf-8f79aac26d02"}}},{"cell_type":"markdown","source":["### Keeping the missing data\nA few machine learning algorithms can easily deal with missing data, let's see what it looks like:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b191cf1b-94ad-4d1e-bf40-a31b56e2e4d5"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('missingdata').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"104af5d4-17ec-4e01-b38f-826be238fd4f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.csv('/FileStore/tables/ContainsNull.csv', header=True, inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77e6601f-3cc0-4e3f-a7ca-bb7395c44ec4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"452b621e-ef46-4c3c-89ea-ddd16dffa02c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp2| null| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp2| null| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Drop the missing data\n\nYou can use the .na functions for missing data. The drop command has the following parameters:\n\n    df.na.drop(how='any', thresh=None, subset=None)\n    \n    * param how: 'any' or 'all'.\n    \n        If 'any', drop a row if it contains any nulls.\n        If 'all', drop a row only if all its values are null.\n    \n    * param thresh: int, default None\n    \n        If specified, drop rows that have less than `thresh` non-null values.\n        This overwrites the `how` parameter.\n        \n    * param subset: \n        optional list of column names to consider."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a9411b7-571e-4661-8bca-81d5ed0d88d6"}}},{"cell_type":"code","source":["# Drop any row that contains missing data\n# Default value is any\ndf.na.drop().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c67f69a-3edb-4838-9f05-c26b57aa4cf2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Has to have at least 2 NON-null values\ndf.na.drop(thresh=2).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed2349d1-b39b-40e7-8c4b-e2427ab6e24e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.na.drop(subset=['Sales']).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27399acd-5384-4e93-8989-d2c93bbf453d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.na.drop(how='all').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e8f7332-432d-46bd-a736-dd40655224d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp2| null| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John| null|\n|emp2| null| null|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Fill the missing values\n\nWe can also fill the missing values with new values. If we have multiple nulls across multiple data types, Spark is actually smart enough to match up the data types. For example:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef97ae71-3048-43f5-aa23-28e1672e0225"}}},{"cell_type":"code","source":["df.na.fill('NEW VALUE').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3afba3c-4fcd-42cd-8be3-307b4bcafdf7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+---------+-----+\n|  Id|     Name|Sales|\n+----+---------+-----+\n|emp1|     John| null|\n|emp2|NEW VALUE| null|\n|emp3|NEW VALUE|345.0|\n|emp4|    Cindy|456.0|\n+----+---------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+---------+-----+\n|  Id|     Name|Sales|\n+----+---------+-----+\n|emp1|     John| null|\n|emp2|NEW VALUE| null|\n|emp3|NEW VALUE|345.0|\n|emp4|    Cindy|456.0|\n+----+---------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.na.fill('No Name', subset=['Name']).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a443e786-1334-483e-a3c5-b94a25186ef0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-------+-----+\n|  Id|   Name|Sales|\n+----+-------+-----+\n|emp1|   John| null|\n|emp2|No Name| null|\n|emp3|No Name|345.0|\n|emp4|  Cindy|456.0|\n+----+-------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-------+-----+\n|  Id|   Name|Sales|\n+----+-------+-----+\n|emp1|   John| null|\n|emp2|No Name| null|\n|emp3|No Name|345.0|\n|emp4|  Cindy|456.0|\n+----+-------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["A very common practice is to fill values with the mean value for the column, for example:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ca85f38-1ea1-4527-b01f-3ade5a37f019"}}},{"cell_type":"code","source":["from pyspark.sql.functions import mean\n\nmean_val = df.select(mean(df['Sales'])).collect()\n\n# Weird nested formatting of Row object!\nmean_val[0][0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88bbd789-fd6e-454a-8fb6-eb8e29c82f08"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[11]: 400.5","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: 400.5"]}}],"execution_count":0},{"cell_type":"code","source":["mean_sales = mean_val[0][0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84dd36bc-5bc2-425d-a986-5ee1f4c77e6d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.na.fill(mean_sales, ['Sales']).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa082c42-2fa9-4594-90b8-307bf424d963"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John|400.5|\n|emp2| null|400.5|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John|400.5|\n|emp2| null|400.5|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Another way to get the same result\ndf.na.fill(df.select(mean(df['Sales'])).collect()[0][0], 'Sales').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47def0df-034d-4b89-b45e-ba0b28368924"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John|400.5|\n|emp2| null|400.5|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+-----+-----+\n|  Id| Name|Sales|\n+----+-----+-----+\n|emp1| John|400.5|\n|emp2| null|400.5|\n|emp3| null|345.0|\n|emp4|Cindy|456.0|\n+----+-----+-----+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"missing_data","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3236194128164549}},"nbformat":4,"nbformat_minor":0}
